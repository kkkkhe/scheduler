import { createEffect, createStore, createApi, sample, scopeBind, is, combine, attach, createEvent, split, merge } from 'effector';

const unknownContract = {
  isData: raw => true,
  getErrorMessages: () => []
};

function _extends() {
  _extends = Object.assign ? Object.assign.bind() : function (target) {
    for (var i = 1; i < arguments.length; i++) {
      var source = arguments[i];

      for (var key in source) {
        if (Object.prototype.hasOwnProperty.call(source, key)) {
          target[key] = source[key];
        }
      }
    }

    return target;
  };
  return _extends.apply(this, arguments);
}

function _objectWithoutPropertiesLoose(source, excluded) {
  if (source == null) return {};
  var target = {};
  var sourceKeys = Object.keys(source);
  var key, i;

  for (i = 0; i < sourceKeys.length; i++) {
    key = sourceKeys[i];
    if (excluded.indexOf(key) >= 0) continue;
    target[key] = source[key];
  }

  return target;
}

function _toPrimitive(input, hint) {
  if (typeof input !== "object" || input === null) return input;
  var prim = input[Symbol.toPrimitive];

  if (prim !== undefined) {
    var res = prim.call(input, hint || "default");
    if (typeof res !== "object") return res;
    throw new TypeError("@@toPrimitive must return a primitive value.");
  }

  return (hint === "string" ? String : Number)(input);
}

function _toPropertyKey(arg) {
  var key = _toPrimitive(arg, "string");

  return typeof key === "symbol" ? key : String(key);
}

function mapValues(val, fn) {
  const mappedEntries = Object.entries(val).map(([key, value]) => [key, fn(value)]);
  return Object.fromEntries(mappedEntries);
}

function zipObject(object) {
  const result = {};

  for (const [key, value] of Object.entries(object)) {
    for (const [k, v] of Object.entries(value)) {
      result[k] = _extends({}, result[k], {
        [key]: v
      });
    }
  }

  return result;
}

function randomNumber({
  min,
  max
}) {
  return Math.random() * (max - min) + min;
}

/**
 * Copy-pasted, original author is https://github.com/AlexandrHoroshih
 */

/**
 * Creates defer - controlled promise
 */
function createDefer() {
  const defer = {
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    resolve: () => {},
    // eslint-disable-next-line @typescript-eslint/no-empty-function
    reject: () => {},
    // @ts-expect-error it will be set later
    promise: null
  };
  defer.promise = new Promise((rs, rj) => {
    defer.resolve = rs;
    defer.reject = rj;
  }); // eslint-disable-next-line @typescript-eslint/no-empty-function

  defer.promise.catch(() => {});
  return defer;
}

function isEmpty(v) {
  return v == undefined;
}
function isNotEmpty(v) {
  return !isEmpty(v);
}

// Source: https://github.com/smelukov/nano-equal
function isEqual(a, b) {
  if (a === b) {
    return true;
  } // is nan


  if (a !== a && b !== b) {
    // eslint-disable-line no-self-compare
    return true;
  }

  const typeA = getType(a);
  const typeB = getType(b);

  if (typeA !== typeB) {
    return false;
  }

  if (typeA === 'pure-object') {
    if (a === b) {
      return true;
    }

    const keysA = Object.keys(a);
    const keysBLength = Object.keys(b).length;

    if (keysA.length !== keysBLength) {
      return false;
    }

    for (let i = 0, l = keysA.length; i < l; i++) {
      const key = keysA[i]; // eslint-disable-next-line no-prototype-builtins

      if (!b.hasOwnProperty(keysA[i])) {
        return false;
      }

      const valA = a[key];
      const valB = b[key]; // handle recursion

      if (valA === a || valB === b || valA === b || valB === a) {
        return valA === valB;
      }

      if (!isEqual(valA, valB)) {
        return false;
      }
    }

    return true;
  } else if (typeA === 'array') {
    if (a.length === b.length) {
      for (let j = 0; j < a.length; j++) {
        const elA = a[j];
        const elB = b[j]; // handle recursion

        if (elA === a || elB === b || elA === b || elB === a) {
          return elA === elB;
        }

        if (!isEqual(elA, elB)) {
          return false;
        }
      }
    } else {
      return false;
    }

    return true;
  } else if (typeA === 'object') {
    if (a.valueOf !== Object.prototype.valueOf() && b.valueOf !== Object.prototype.valueOf()) {
      return a.valueOf() === b.valueOf();
    }

    if (a.toString !== Object.prototype.toString() && b.toString !== Object.prototype.toString()) {
      return a.toString() === b.toString();
    }
  }

  return false;
}

function isArrayLike(a) {
  if (Array.isArray(a)) {
    return true;
  }

  const len = a.length;

  if (typeof len === 'number' && len > -1) {
    if (len) {
      return 0 in a && len - 1 in a;
    }

    return true;
  }

  return false;
}

function getType(a) {
  const type = typeof a;

  if (type === 'object') {
    if (a === null) {
      return 'null';
    } else if (isArrayLike(a)) {
      return 'array';
    } else if (a.constructor === Object) {
      return 'pure-object';
    }

    return 'object';
  }

  return type;
}

function divide(items, predicate) {
  const left = [];
  const right = [];

  for (const item of items) {
    if (predicate(item)) {
      left.push(item);
    } else {
      right.push(item);
    }
  }

  return [left, right];
}

function get(path) {
  return obj => obj[path];
}

const INVALID_DATA = 'INVALID_DATA';
const TIMEOUT = 'TIMEOUT';
const ABORT = 'ABORT';
const PREPARATION = 'PREPARATION';
const HTTP = 'HTTP';
const NETWORK = 'NETWORK';

function invalidDataError(config) {
  return _extends({}, config, {
    errorType: INVALID_DATA,
    explanation: 'Response was considered as invalid against a given contract'
  });
}
function timeoutError(config) {
  return _extends({}, config, {
    errorType: TIMEOUT,
    explanation: 'Request was cancelled due to timeout'
  });
}
function abortError() {
  return {
    errorType: ABORT,
    explanation: 'Request was cancelled due to concurrency policy'
  };
}
function preparationError(config) {
  return _extends({}, config, {
    errorType: PREPARATION,
    explanation: 'Extraction of data from the response was failed'
  });
}
function httpError(config) {
  return _extends({}, config, {
    errorType: HTTP,
    explanation: 'Request was finished with unsuccessful HTTP code'
  });
}
function networkError(config) {
  return _extends({}, config, {
    errorType: NETWORK,
    explanation: 'Request was failed due to network problems'
  });
}

let count = 0;

const getId = () => {
  count += 1;
  return count;
};

const createAborter = () => {
  let handlers = [];

  const onAbort = fn => {
    handlers.push(fn);
    return () => {
      const idx = handlers.findIndex(f => f === fn);

      if (idx > -1) {
        handlers.splice(idx, 1);
      }
    };
  };

  const runAborters = () => {
    handlers.forEach(f => f());
    handlers = [];
  };

  return {
    runAborters,
    onAbort
  };
};

const createCall = ctx => {
  const def = createDefer();
  def.context = ctx;
  return def;
};

function abortable(config) {
  var _a, _b;

  const {
    abort,
    effect
  } = config;
  const runCallFx = createEffect(async def => {
    const result = await def.promise;
    return result;
  });
  const $calls = createStore([], {
    serialize: 'ignore'
  });
  const callsApi = createApi($calls, {
    add(calls, def) {
      return [...calls, def];
    },

    remove(calls, def) {
      return calls.filter(d => d !== def);
    }

  });

  if (abort === null || abort === void 0 ? void 0 : abort.signal) {
    const abortTrigger = sample({
      clock: abort.signal
    });
    $calls.watch(abortTrigger, calls => {
      calls.forEach(c => {
        var _a, _b;

        (_b = (_a = c.context) === null || _a === void 0 ? void 0 : _a.runAborters) === null || _b === void 0 ? void 0 : _b.call(_a);
        c.reject(abortError());
      });
    });
  } // нужно, чтобы поддержать и синхронные эффекты тоже


  const handler = async (...args) => effect(...args);

  const runnerFx = createEffect({
    name: (_a = config.name) !== null && _a !== void 0 ? _a : 'runnerFx',
    sid: ((_b = config.name) !== null && _b !== void 0 ? _b : 'runnerFx') + getId(),
    handler: async p => {
      const {
        runAborters,
        onAbort
      } = createAborter();
      const call = createCall({
        runAborters
      });
      callsApi.add(call);
      let boundApiRemove;

      try {
        boundApiRemove = scopeBind(callsApi.remove);
      } catch (e) {
        boundApiRemove = callsApi.remove;
      }

      handler(p, {
        onAbort
      }).then(call.resolve).catch(call.reject).finally(() => boundApiRemove(call));
      const result = await runCallFx(call);
      return result;
    }
  });
  return runnerFx;
}

function normalizeSourced({
  field,
  clock,
  source
}) {
  let $target = createStore(null, {
    serialize: 'ignore'
  });

  if (clock) {
    if (field === undefined) ; else if (is.store(field)) {
      const $storeField = field;
      sample({
        clock,
        source: $storeField,
        target: $target
      });
    } else if ((field === null || field === void 0 ? void 0 : field.source) && (field === null || field === void 0 ? void 0 : field.fn)) {
      const callbackField = field;
      sample({
        clock,
        source: callbackField.source,
        fn: (source, params) => callbackField.fn(params, source),
        target: $target
      });
    } else if (typeof field === 'function') {
      const callbackField = field;
      sample({
        clock,
        fn: data => callbackField(data),
        target: $target
      });
    } else {
      const valueField = field;
      sample({
        clock,
        fn: () => valueField,
        target: $target
      });
    }
  }

  if (source) {
    const $source = source;

    if (field === undefined) ; else if (is.store(field)) {
      const $storeField = field;
      $target = $storeField;
    } else if ((field === null || field === void 0 ? void 0 : field.source) && (field === null || field === void 0 ? void 0 : field.fn)) {
      const callbackField = field;
      $target = combine($source, callbackField.source, callbackField.fn);
    } else if (typeof field === 'function') {
      const callbackField = field;
      $target = $source.map(callbackField);
    } else {
      const valueField = field;
      $target = createStore(valueField, {
        serialize: 'ignore'
      });
    }
  }

  return $target;
} // -- Reader case --


function createSourcedReader(field) {
  let readFx;

  if (field === undefined) {
    readFx = createEffect(async _params => null);
  } else if (is.store(field)) {
    const $storeField = field;
    readFx = attach({
      source: $storeField,

      async effect(source, _params) {
        return source;
      }

    });
  } else if (field.source && field.fn) {
    const callbackField = field;
    readFx = attach({
      source: callbackField.source,

      async effect(source, params) {
        return callbackField.fn(params, source);
      }

    });
  } else if (typeof field === 'function') {
    const callbackField = field;
    readFx = createEffect(async params => callbackField(params));
  } else {
    const valueField = field;
    readFx = createEffect(async _params => valueField);
  }

  return readFx;
}

function normalizeStaticOrReactive(v) {
  if (!v) {
    return createStore(null, {
      serialize: 'ignore'
    });
  }

  if (is.store(v)) {
    return v;
  }

  return createStore(v, {
    serialize: 'ignore'
  });
} // -- Extract source


function extractSource(sourced) {
  if (is.store(sourced)) {
    return sourced;
  }

  if (sourced === null || sourced === void 0 ? void 0 : sourced.source) {
    return sourced.source;
  }

  return null;
} // -- Combine sourced
// TODO: type it https://github.com/igorkamyshev/farfetched/issues/281


function combineSourced(config, mapper) {
  const megaStore = {};
  const megaFns = {};

  for (const [key, value] of Object.entries(config)) {
    if (is.store(value)) {
      megaStore[key] = value;
    } else if ((value === null || value === void 0 ? void 0 : value.source) && (value === null || value === void 0 ? void 0 : value.fn)) {
      megaStore[key] = value.source;
      megaFns[key] = value.fn;
    } else if (typeof value === 'function') {
      megaFns[key] = value;
    } else {
      // plain value
      megaStore[key] = value;
    }
  }

  const $megaSource = combine(megaStore);
  return {
    source: $megaSource,
    fn: (data, source) => {
      const result = {};

      for (const key of Object.keys(config)) {
        if (key in source) {
          result[key] = source[key];
        }

        if (key in megaFns) {
          result[key] = megaFns[key](data, source[key]);
        }
      }

      if (mapper) {
        return mapper(result);
      } else {
        return result;
      }
    }
  };
} // -- Exports --

function delay({
  clock,
  timeout,
  target = createEvent()
}) {
  const timerFx = createEffect(({
    payload,
    milliseconds
  }) => new Promise(resolve => {
    setTimeout(resolve, milliseconds, payload);
  }));
  sample({
    source: normalizeStaticOrReactive(timeout),
    clock,
    fn: (milliseconds, payload) => ({
      payload,
      milliseconds
    }),
    target: timerFx
  });
  sample({
    clock: timerFx.doneData,
    target: target
  });
  return target;
}

function every(configOrStores, predicateOrNone) {
  let stores = [];

  let predicate = () => false;

  if (Array.isArray(configOrStores)) {
    stores = configOrStores;
    predicate = predicateOrNone;
  } else if (Array.isArray(configOrStores.stores)) {
    stores = configOrStores.stores;
    predicate = configOrStores.predicate;
  }

  let checker;

  if (isFunction(predicate)) {
    checker = predicate;
  } else if (is.store(predicate)) {
    checker = predicate.map(value => required => value === required);
  } else {
    checker = value => value === predicate;
  }

  const $values = combine(stores); // Combine pass simple values as is

  const $checker = checker;
  return combine($checker, $values, (checker, values) => values.every(checker));
}

function isFunction(value) {
  return typeof value === 'function';
}

function not(source) {
  return source.map(value => !value);
}

function and(...stores) {
  return every({
    predicate: true,
    stores
  });
}

/**
 * Откладывает выполнение события до переданного указанного стора в состояние `true`
 *
 * @returns событие, которое будет вызывано после вызова clock, когда until будет true
 */

function postpone({
  clock,
  until
}) {
  const target = createEvent();
  const $fired = createStore(false, {
    serialize: 'ignore'
  }).on(target, () => true).on(clock, () => false);
  sample({
    clock: [clock, until],
    source: clock,
    filter: and(until, not($fired)),
    target
  });
  return target;
}

function serializationForSideStore(serialize) {
  if (serialize === 'ignore') {
    return 'ignore';
  }

  return undefined;
}

const readNowFx = createEffect(() => Date.now());
function time({
  clock
}) {
  const $time = createStore(Date.now());
  sample({
    clock: clock,
    fn: () => {// nothing
    },
    target: readNowFx
  });
  sample({
    clock: readNowFx.doneData,
    target: $time
  });
  return $time;
}

// Copied and adopted https://github.com/effector/patronum/blob/main/src/debounce/index.ts
function syncBatch(clock) {
  const saveTimeoutId = createEvent();
  const $timeoutId = createStore(null, {
    serialize: 'ignore'
  }).on(saveTimeoutId, (_, id) => id);
  const saveReject = createEvent();
  const $rejecter = createStore(null, {
    serialize: 'ignore'
  }).on(saveReject, (_, rj) => rj);
  const tick = createEvent();
  const timerFx = attach({
    source: {
      timeoutId: $timeoutId,
      rejectPromise: $rejecter
    },
    effect: ({
      timeoutId,
      rejectPromise
    }) => {
      if (timeoutId) clearTimeout(timeoutId);
      if (rejectPromise) rejectPromise();
      return new Promise((resolve, reject) => {
        saveReject(reject);
        saveTimeoutId(setTimeout(resolve, 0));
      });
    }
  });
  $rejecter.reset(timerFx.done);
  $timeoutId.reset(timerFx.done); // It's ok - nothing will ever start unless source is triggered

  const $payload = createStore([], {
    serialize: 'ignore'
  }).on(clock, (_, payload) => [payload]);
  const $canTick = createStore(true, {
    serialize: 'ignore'
  });
  const triggerTick = createEvent();
  $canTick.on(triggerTick, () => false).on([tick, // debounce timeout can be restarted in later ticks
  timerFx], () => true);
  sample({
    clock: clock,
    filter: $canTick,
    target: triggerTick
  });
  sample({
    clock: triggerTick,
    target: timerFx
  });
  sample({
    source: $payload,
    clock: timerFx.done,
    fn: ([payload]) => payload,
    target: tick
  });
  return tick;
}

function createContractApplier(contract) {
  const applyContractFx = createEffect({
    handler: ({
      result: data
    }) => {
      const isData = contract.isData(data);

      if (!isData) {
        throw invalidDataError({
          validationErrors: contract.getErrorMessages(data),
          response: data
        });
      }

      return data;
    },
    sid: 'ff.applyContractFx'
  });
  return applyContractFx;
}

function checkValidationResult(result) {
  if (result === true) {
    return true;
  }

  if (Array.isArray(result) && result.length === 0) {
    return true;
  }

  if (typeof result === 'string' && result.length === 0) {
    return true;
  }

  return false;
}

function unwrapValidationResult(result) {
  if (result === true) {
    return [];
  }

  if (result === false) {
    return ['Invalid data'];
  }

  if (!Array.isArray(result)) {
    return [result];
  }

  if (result.length === 0) {
    return [];
  }

  return result;
}

const validValidator = () => true;

function createRemoteOperation({
  name: ownName,
  meta,
  kind,
  serialize,
  enabled,
  contract,
  validate,
  mapData,
  sourced,
  paramsAreMeaningless
}) {
  const revalidate = createEvent();
  const applyContractFx = createContractApplier(contract);
  const name = ownName !== null && ownName !== void 0 ? ownName : 'unnamed'; // Dummy effect, it will be replaced with real in head-full factory

  const executeFx = createEffect({
    handler: () => {
      throw new Error('Not implemented');
    },
    sid: `ff.${name}.executeFx`,
    name: `${name}.executeFx`
  });
  const remoteDataSoruce = {
    name: 'remote_source',
    get: createEffect(async ({
      params
    }) => {
      const result = await executeFx(params);
      return {
        result,
        stale: false
      };
    })
  };
  const dataSources = [remoteDataSoruce];
  const {
    retrieveDataFx,
    notifyAboutNewValidDataFx,
    notifyAboutDataInvalidationFx
  } = createDataSourceHandlers(dataSources);
  /*
   * Start event, it's used as it or to pipe it in head-full factory
   *
   * sample({
   *  clock: externalStart,
   *  target: headlessQuery.start,
   *  greedy: true
   * })
   */

  const start = createEvent(); // Signal-events

  const finished = {
    success: createEvent(),
    failure: createEvent(),
    skip: createEvent(),
    finally: createEvent()
  }; // -- Main stores --

  const $status = createStore('initial', {
    sid: `ff.${name}.$status`,
    name: `${name}.$status`,
    serialize
  });
  const $enabled = normalizeStaticOrReactive(enabled !== null && enabled !== void 0 ? enabled : true).map(Boolean);
  const $latestParams = createStore(null, {
    serialize: 'ignore'
  }); // -- Derived stores --

  const $idle = $status.map(status => status === 'initial');
  const $pending = $status.map(status => status === 'pending');
  const $failed = $status.map(status => status === 'fail');
  const $succeeded = $status.map(status => status === 'done'); // -- Indicate status --

  sample({
    clock: [retrieveDataFx.map(() => 'pending'), finished.success.map(() => 'done'), finished.failure.map(() => 'fail')],
    target: $status
  });
  sample({
    clock: start,
    filter: $enabled,
    target: $latestParams
  }); // -- Execution flow

  sample({
    clock: start,
    filter: not($enabled),

    fn(params) {
      return {
        params,
        meta: {
          stopErrorPropagation: false,
          stale: false
        }
      };
    },

    target: finished.skip
  });
  sample({
    clock: revalidate,
    target: notifyAboutDataInvalidationFx
  });
  sample({
    clock: notifyAboutDataInvalidationFx.finally,
    source: revalidate,
    filter: ({
      refresh
    }) => refresh,
    fn: ({
      params
    }) => params,
    target: start
  });
  sample({
    clock: start,
    filter: $enabled,
    fn: params => ({
      params
    }),
    target: retrieveDataFx
  });
  sample({
    clock: retrieveDataFx.done,
    fn: ({
      params,
      result
    }) => ({
      params: params.params,
      result: result.result,
      meta: {
        stopErrorPropagation: false,
        stale: result.stale
      }
    }),
    filter: $enabled,
    target: applyContractFx
  });
  sample({
    clock: retrieveDataFx.fail,
    fn: ({
      error,
      params
    }) => ({
      error: error,
      params: params.params,
      meta: {
        stopErrorPropagation: false,
        stale: false
      }
    }),
    filter: $enabled,
    target: finished.failure
  });
  const {
    validDataRecieved,
    __: invalidDataRecieved
  } = split(sample({
    clock: applyContractFx.done,
    source: normalizeSourced({
      field: validate !== null && validate !== void 0 ? validate : validValidator,
      clock: applyContractFx.done.map(({
        result,
        params
      }) => ({
        result,
        params: params.params // Extract original params, it is params of params

      }))
    }),
    fn: (validation, {
      params,
      result
    }) => ({
      result,
      // Extract original params, it is params of params
      params: params.params,
      validation,
      meta: params.meta
    })
  }), {
    validDataRecieved: ({
      validation
    }) => checkValidationResult(validation)
  });
  sample({
    clock: validDataRecieved,
    source: normalizeSourced({
      field: mapData,
      clock: validDataRecieved
    }),
    fn: (result, {
      params,
      meta
    }) => ({
      result,
      params,
      meta
    }),
    target: finished.success
  });
  sample({
    clock: finished.success,
    filter: ({
      meta
    }) => meta.stale,
    fn: ({
      params
    }) => ({
      params,
      skipStale: true
    }),
    target: retrieveDataFx
  });
  sample({
    clock: validDataRecieved,
    filter: ({
      meta
    }) => !meta.stale,
    target: notifyAboutNewValidDataFx
  });
  sample({
    clock: applyContractFx.fail,
    filter: ({
      params
    }) => !params.meta.stopErrorPropagation,
    fn: ({
      error,
      params
    }) => ({
      error,
      // Extract original params, it is params of params
      params: params.params,
      meta: params.meta
    }),
    target: finished.failure
  });
  sample({
    clock: invalidDataRecieved,
    filter: ({
      meta
    }) => !meta.stopErrorPropagation,
    fn: ({
      params,
      validation,
      meta,
      result
    }) => ({
      params,
      error: invalidDataError({
        validationErrors: unwrapValidationResult(validation),
        response: result
      }),
      meta
    }),
    target: finished.failure
  }); // Emit skip for disabling in-flight operation

  sample({
    clock: $enabled.updates,
    source: start,
    filter: not($enabled),
    fn: params => ({
      params,
      meta: {
        stopErrorPropagation: false,
        stale: true
      }
    }),
    target: finished.skip
  }); // -- Send finally --

  sample({
    clock: [finished.success, finished.failure, finished.skip],

    fn({
      params,
      meta
    }) {
      return {
        params,
        meta
      };
    },

    target: finished.finally
  });
  return {
    start,
    finished,
    $status,
    $idle,
    $pending,
    $failed,
    $succeeded,
    $enabled,
    __: {
      executeFx,
      meta: _extends({}, meta, {
        name
      }),
      kind,
      $latestParams,
      lowLevelAPI: {
        dataSources,
        dataSourceRetrieverFx: retrieveDataFx,
        sourced: sourced !== null && sourced !== void 0 ? sourced : [],
        paramsAreMeaningless: paramsAreMeaningless !== null && paramsAreMeaningless !== void 0 ? paramsAreMeaningless : false,
        revalidate
      }
    }
  };
}

function createDataSourceHandlers(dataSources) {
  const retrieveDataFx = createEffect({
    handler: async ({
      params,
      skipStale
    }) => {
      for (const dataSource of dataSources) {
        const fromSource = await dataSource.get({
          params
        });

        if (skipStale && (fromSource === null || fromSource === void 0 ? void 0 : fromSource.stale)) {
          continue;
        }

        if (fromSource) {
          return fromSource;
        }
      }

      throw new Error('No data source returned data');
    }
  });
  const notifyAboutNewValidDataFx = createEffect({
    handler: async ({
      params,
      result
    }) => {
      await Promise.all(dataSources.map(get('set')).filter(Boolean).map(set => set({
        params,
        result
      })));
    }
  });
  const notifyAboutDataInvalidationFx = createEffect({
    handler: async ({
      params
    }) => {
      await Promise.all(dataSources.map(get('unset')).filter(Boolean).map(unset => unset({
        params
      })));
    }
  });
  return {
    retrieveDataFx,
    notifyAboutNewValidDataFx,
    notifyAboutDataInvalidationFx
  };
}

const QuerySymbol = Symbol('Query');
function isQuery(value) {
  var _a;

  return ((_a = value === null || value === void 0 ? void 0 : value.__) === null || _a === void 0 ? void 0 : _a.kind) === QuerySymbol;
}

const _excluded$1 = ["params"];
/**
 * Creates Query without any executor, it cannot be used as-is.
 *
 * @example
 * const headlessQuery = createHeadlessQuery()
 * headlessQuery.__.executeFx.use(someHandler)
 */

function createHeadlessQuery(config) {
  const {
    initialData: initialDataRaw,
    contract,
    mapData,
    enabled,
    validate,
    name,
    serialize,
    sourced,
    paramsAreMeaningless
  } = config;
  const initialData = initialDataRaw !== null && initialDataRaw !== void 0 ? initialDataRaw : null;
  const operation = createRemoteOperation({
    name,
    kind: QuerySymbol,
    serialize: serializationForSideStore(serialize),
    enabled,
    meta: {
      serialize,
      initialData
    },
    contract,
    validate,
    mapData,
    sourced,
    paramsAreMeaningless
  });
  const refresh = createEvent();
  const reset = createEvent(); // -- Main stores --

  const $data = createStore(initialData, {
    sid: `ff.${operation.__.meta.name}.$data`,
    name: `${operation.__.meta.name}.$data`,
    serialize
  });
  const $error = createStore(null, {
    sid: `ff.${operation.__.meta.name}.$error`,
    name: `${operation.__.meta.name}.$error`,
    serialize: serializationForSideStore(serialize)
  });
  const $stale = createStore(true, {
    sid: `ff.${operation.__.meta.name}.$stale`,
    name: `${operation.__.meta.name}.$stale`,
    serialize: serializationForSideStore(serialize)
  });
  sample({
    clock: operation.finished.success,
    fn: () => null,
    target: $error
  });
  sample({
    clock: operation.finished.success,
    fn: ({
      result
    }) => result,
    target: $data
  });
  $data.reset(operation.finished.failure);
  sample({
    clock: operation.finished.failure,
    fn: ({
      error
    }) => error,
    target: $error
  }); // -- Handle stale

  sample({
    clock: operation.finished.finally,
    fn: ({
      meta
    }) => meta.stale,
    target: $stale
  }); // -- Trigger API

  const postponedRefresh = postpone({
    clock: refresh,
    until: operation.$enabled
  });
  sample({
    clock: postponedRefresh,
    source: {
      stale: $stale,
      latestParams: operation.__.$latestParams
    },
    filter: ({
      stale,
      latestParams
    }, params) => stale || !isEqual(params !== null && params !== void 0 ? params : null, latestParams),
    fn: (_, params) => params,
    target: operation.start
  }); // -- Reset state --

  sample({
    clock: reset,
    target: [$data.reinit, $error.reinit, $stale.reinit, operation.$status.reinit]
  }); // -- Protocols --

  const unitShape = {
    data: $data,
    error: $error,
    stale: $stale,
    pending: operation.$pending,
    start: operation.start
  };

  const unitShapeProtocol = () => unitShape; // Experimental API, won't be exposed as protocol for now


  const attachProtocol = ({
    source,
    mapParams
  }) => {
    const attachedQuery = createHeadlessQuery(config);

    attachedQuery.__.lowLevelAPI.dataSourceRetrieverFx.use(attach({
      source,
      mapParams: (_ref, sourceValue) => {
        let {
          params
        } = _ref,
            rest = _objectWithoutPropertiesLoose(_ref, _excluded$1);

        return _extends({
          params: mapParams ? mapParams(params, sourceValue) : params
        }, rest);
      },
      effect: operation.__.lowLevelAPI.dataSourceRetrieverFx
    }));

    return attachedQuery;
  }; // -- Public API --


  return _extends({
    $data,
    $error,
    $stale,
    reset,
    refresh
  }, operation, {
    __: _extends({}, operation.__, {
      experimentalAPI: {
        attach: attachProtocol
      }
    }),
    '@@unitShape': unitShapeProtocol
  });
}

function resolveExecuteEffect(config) {
  const anyConfig = config;

  if (is.effect(anyConfig.effect)) {
    return anyConfig.effect;
  } else if (typeof anyConfig.handler === 'function') {
    return createEffect(anyConfig.handler);
  }

  throw new InvalidConfigException('handler or effect must be passed to the config');
}

class InvalidConfigException extends Error {
  constructor(message) {
    super(message);
  }

}

function createQuery( // Use any because of overloads
// eslint-disable-next-line @typescript-eslint/no-explicit-any
config) {
  var _a, _b, _c;

  const query = createHeadlessQuery({
    initialData: (_a = config.initialData) !== null && _a !== void 0 ? _a : null,
    contract: (_b = config.contract) !== null && _b !== void 0 ? _b : unknownContract,
    mapData: (_c = config.mapData) !== null && _c !== void 0 ? _c : ({
      result
    }) => result,
    enabled: config.enabled,
    validate: config.validate,
    name: config.name,
    serialize: config.serialize
  });

  query.__.executeFx.use(resolveExecuteEffect(config));

  return query;
}

function connectQuery(args) {
  const {
    source,
    target
  } = args; // Settings

  const singleParentMode = isQuery(source); // Participants

  const children = Array.isArray(target) ? target : [target];
  const parents = singleParentMode ? [source] : Object.values(source);
  const mapperFn = args === null || args === void 0 ? void 0 : args.fn; // Helper untis

  const anyParentStarted = merge(parents.map(query => query.start));
  const anyParentSuccessfullyFinished = merge(parents.map(query => query.finished.success));
  const $allParentsHaveData = every({
    stores: parents.map(query => query.$data),
    predicate: data => data !== null
  });
  const $allParentDataDictionary = singleParentMode ? source.$data : combine(mapValues(source, query => query.$data));
  const $allParentParamsDictionary = createStore(null, {
    serialize: 'ignore'
  });

  if (singleParentMode) {
    sample({
      clock: source.finished.success,
      fn: ({
        params
      }) => params,
      target: $allParentParamsDictionary
    });
  } else {
    for (const [parentName, parentFinishedSuccess] of Object.entries(mapValues(source, query => query.finished.success))) {
      sample({
        clock: parentFinishedSuccess,
        source: $allParentParamsDictionary,
        fn: (latestParams, {
          params
        }) => _extends({}, latestParams, {
          [parentName]: params
        }),
        target: $allParentParamsDictionary
      });
    }
  } // Relations


  sample({
    clock: anyParentStarted,

    fn() {
      return true;
    },

    target: children.map(t => t.$stale)
  });
  sample({
    clock: postpone({
      clock: anyParentSuccessfullyFinished,
      until: $allParentsHaveData
    }),
    source: {
      data: $allParentDataDictionary,
      params: $allParentParamsDictionary
    },

    fn({
      data,
      params
    }) {
      var _a;

      const mapped = mapperFn === null || mapperFn === void 0 ? void 0 : mapperFn(singleParentMode ? {
        result: data,
        params
      } : zipObject({
        result: data,
        params
      }));
      return (_a = mapped === null || mapped === void 0 ? void 0 : mapped.params) !== null && _a !== void 0 ? _a : null;
    },

    target: children.map(t => t.start)
  });
}

function isInvalidDataError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === INVALID_DATA;
}
function isTimeoutError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === TIMEOUT;
}
function isAbortError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === ABORT;
}
function isPreparationError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === PREPARATION;
}
function isHttpError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === HTTP;
}
function isHttpErrorCode(code) {
  return function isExactHttpError(args) {
    if (!isHttpError(args)) {
      return false;
    }

    return args.error.status === code;
  };
}
function isNetworkError(args) {
  var _a;

  return ((_a = args.error) === null || _a === void 0 ? void 0 : _a.errorType) === NETWORK;
}

/* eslint-disable no-continue */

/**
 * Inlined library
 * https://github.com/jacobheun/any-signal
 */
function anySignal(...signals) {
  const controller = new AbortController();

  function onAbort() {
    controller.abort();

    for (const signal of signals) {
      if (!signal || !signal.removeEventListener) continue;
      signal.removeEventListener('abort', onAbort);
    }
  }

  for (const signal of signals) {
    if (!signal || !signal.addEventListener) continue;

    if (signal.aborted) {
      onAbort();
      break;
    }

    signal.addEventListener('abort', onAbort);
  }

  return controller.signal;
}

/**
 * Inlined library
 * https://github.com/jacobheun/timeout-abort-controller/
 */
class TimeoutController extends AbortController {
  constructor(timeout) {
    super();
    this.timeout = timeout;
    this.timer = setTimeout(() => this.abort(), timeout); // Patch for safari not supported extending built in classes

    Object.setPrototypeOf(this, TimeoutController.prototype);
  }

  abort() {
    this.clear();
    return super.abort();
  }

  clear() {
    clearTimeout(this.timer);
  }

}

function mergeRecords(...records) {
  const final = {};

  for (const item of records) {
    if (typeof item !== 'object') {
      continue;
    }

    for (const [key, value] of Object.entries(item || {})) {
      if (final[key]) {
        final[key] = [final[key], clearValue(value)].flat();
      } else {
        final[key] = clearValue(value);
      }
    }
  }

  return final;
}
function mergeQueryStrings(...queryStrings) {
  const final = [];

  for (const item of queryStrings) {
    if (!item) {
      continue;
    }

    let curr;

    if (typeof item !== 'string') {
      curr = recordToUrlSearchParams(item).toString();
    } else {
      curr = item;
    }

    final.push(curr);
  }

  return final.join('&');
}
function formatHeaders(headersRecord) {
  const headers = new Headers();

  for (const [key, value] of Object.entries(headersRecord)) {
    const cleanValue = clearValue(value);

    if (Array.isArray(cleanValue)) {
      for (const v of cleanValue) {
        headers.append(key, v);
      }
    } else {
      headers.append(key, cleanValue);
    }
  }

  return headers;
}
function formatUrl(url, queryRecord) {
  let queryString;

  if (typeof queryRecord === 'string') {
    queryString = queryRecord;
  } else {
    queryString = recordToUrlSearchParams(queryRecord).toString();
  }

  if (!queryString) {
    return url;
  }

  return `${url}?${queryString}`;
}

function recordToUrlSearchParams(record) {
  const params = new URLSearchParams();

  for (const [key, value] of Object.entries(record)) {
    const cleanValue = clearValue(value);

    if (Array.isArray(cleanValue)) {
      for (const v of cleanValue) {
        params.append(key, v);
      }
    } else {
      params.append(key, cleanValue);
    }
  }

  return params;
}

function clearValue(value) {
  if (typeof value === 'number' || typeof value === 'boolean') {
    return value.toString();
  }

  return value;
}

/**
 * Effect wrapper for Fetch API
 *
 * It's used to declare static type of Error and mock requests in tests
 */

const fetchFx = createEffect({
  sid: 'ff.fetchFx',
  handler: globalThis.fetch
});

/**
 * Basic request effect around fetchFx, with some additional features:
 * + it throws error if response status is 4XX/5XX
 * + it throws serializable NetworkError instead of TypeError
 */

const requestFx = createEffect({
  handler: async request => {
    var _a;

    const response = await fetchFx(request).catch(cause => {
      var _a;

      throw networkError({
        reason: (_a = cause === null || cause === void 0 ? void 0 : cause.message) !== null && _a !== void 0 ? _a : null,
        cause
      });
    });

    if (!response.ok) {
      throw httpError({
        status: response.status,
        statusText: response.statusText,
        response: (_a = await response.text().catch(() => null)) !== null && _a !== void 0 ? _a : null
      });
    }

    return response;
  },
  sid: 'ff.requestFx'
});

function createApiRequest(config) {
  var _a, _b, _c;

  const prepareFx = createEffect(config.response.extract);
  const $haveToBeAborted = createStore(false, {
    serialize: 'ignore'
  });
  const apiRequestFx = createEffect(async ({
    url,
    method,
    query,
    headers,
    credentials,
    body,
    onAbort,
    timeoutController,
    haveToBeAborted
  }) => {
    const abortController = new AbortController();
    onAbort(() => {
      abortController.abort();
    });

    if (haveToBeAborted) {
      throw abortError();
    }

    const mappedBody = body ? config.request.mapBody(body) : null;
    const request = new Request(formatUrl(url, query), {
      method,
      headers: formatHeaders(headers),
      credentials,
      body: mappedBody,
      signal: anySignal(abortController.signal, timeoutController === null || timeoutController === void 0 ? void 0 : timeoutController.signal)
    });
    const response = await requestFx(request).catch(cause => {
      if (timeoutController === null || timeoutController === void 0 ? void 0 : timeoutController.signal.aborted) {
        throw timeoutError({
          timeout: timeoutController.timeout
        });
      }

      if (config.response.transformError) {
        throw config.response.transformError(cause);
      }

      throw cause;
    }); // We cannot read body of the response twice (prepareFx and throw preparationError)

    const clonedResponse = response.clone();
    const prepared = await prepareFx(response).catch(async cause => {
      var _a;

      throw preparationError({
        response: await clonedResponse.text(),
        reason: (_a = cause === null || cause === void 0 ? void 0 : cause.message) !== null && _a !== void 0 ? _a : null
      });
    });

    if (config.response.status) {
      const expected = Array.isArray(config.response.status.expected) ? config.response.status.expected : [config.response.status.expected];

      if (!expected.includes(response.status)) {
        throw invalidDataError({
          validationErrors: [`Expected response status has to be one of [${expected.join(', ')}], got ${response.status}`],
          response: prepared
        });
      }
    }

    return prepared;
  });
  const boundApiRequestFx = attach({
    source: {
      url: normalizeStaticOrReactive(config.request.url),
      method: normalizeStaticOrReactive(config.request.method),
      query: normalizeStaticOrReactive(config.request.query),
      headers: normalizeStaticOrReactive(config.request.headers),
      credentials: normalizeStaticOrReactive(config.request.credentials),
      body: normalizeStaticOrReactive(config.request.body),
      timeout: normalizeStaticOrReactive((_a = config.abort) === null || _a === void 0 ? void 0 : _a.timeout),
      haveToBeAborted: $haveToBeAborted
    },

    mapParams(dynamicConfig, staticConfig) {
      // Exclusive settings
      var _a, _b, _c;

      const url = (_a = staticConfig.url) !== null && _a !== void 0 ? _a : // @ts-expect-error TS cannot infer type correctly, but there is always field in staticConfig or dynamicConfig
      dynamicConfig.url;
      const credentials = (_b = staticConfig.credentials) !== null && _b !== void 0 ? _b : // @ts-expect-error TS cannot infer type correctly, but there is always field in staticConfig or dynamicConfig
      dynamicConfig.credentials;
      const body = (_c = staticConfig.body) !== null && _c !== void 0 ? _c : // @ts-expect-error TS cannot infer type correctly, but there is always field in staticConfig or dynamicConfig
      dynamicConfig.body; // Inclusive settings

      const query = mergeQueryStrings(staticConfig.query, dynamicConfig.query);
      const headers = mergeRecords(staticConfig.headers, dynamicConfig.headers); // Other settings

      const {
        method,
        haveToBeAborted
      } = staticConfig;
      const {
        onAbort
      } = dynamicConfig; // This abort controller uses for timeout, it cancell only one request
      // so we have to create it dynamically

      const timeoutController = staticConfig.timeout ? new TimeoutController(staticConfig.timeout) : null;
      return {
        url,
        method: method,
        query,
        headers,
        credentials,
        body,
        onAbort,
        timeoutController,
        haveToBeAborted
      };
    },

    effect: apiRequestFx
  });
  const abortSignal = createEvent();
  const boundAbortableApiRequestFx = abortable({
    abort: {
      signal: abortSignal
    },

    effect(params, abortContext) {
      return boundApiRequestFx(_extends({}, params, abortContext));
    }

  }); // Apply concurrency and abort settings

  if ((_b = config.abort) === null || _b === void 0 ? void 0 : _b.clock) {
    sample({
      clock: config.abort.clock,
      target: abortSignal
    });
  }

  switch ((_c = config.concurrency) === null || _c === void 0 ? void 0 : _c.strategy) {
    case 'TAKE_LATEST':
      sample({
        clock: boundAbortableApiRequestFx,
        target: abortSignal
      });
      break;

    case 'TAKE_FIRST':
      sample({
        clock: apiRequestFx,
        fn: () => true,
        target: $haveToBeAborted
      });
      sample({
        clock: boundAbortableApiRequestFx.finally,
        fn: () => false,
        target: $haveToBeAborted
      });
      break;

  }

  return boundAbortableApiRequestFx;
}

function createJsonApiRequest(config) {
  var _a; // Add default application/json header to every request


  const $headers = combine({
    method: normalizeStaticOrReactive(config.request.method),
    headers: normalizeStaticOrReactive(config.request.headers)
  }, ({
    method,
    headers
  }) => ['GET', 'HEAD'].includes(method) // TODO: fix type inferences
  ? headers : mergeRecords(headers, {
    'Content-Type': 'application/json'
  }));
  const jsonApiCallFx = createApiRequest(_extends({}, config, {
    request: _extends({}, config.request, {
      headers: $headers,
      // Serialize body to JSON-string
      mapBody: jsonBody => JSON.stringify(jsonBody)
    }),
    response: {
      extract: async response => {
        const emptyContent = await isEmptyResponse(response);

        if (emptyContent) {
          return null;
        }

        return response.json();
      },
      transformError: error => {
        if (!isHttpError({
          error
        })) {
          return error;
        }

        const errorAsHttpError = error;

        if (typeof errorAsHttpError.response !== 'string') {
          return errorAsHttpError;
        }

        try {
          const parsedError = JSON.parse(errorAsHttpError.response);
          return httpError({
            status: errorAsHttpError.status,
            statusText: errorAsHttpError.statusText,
            response: parsedError
          });
        } catch (e) {
          return errorAsHttpError;
        }
      },
      status: (_a = config.response) === null || _a === void 0 ? void 0 : _a.status
    }
  }));
  return jsonApiCallFx;
}

async function isEmptyResponse(response) {
  if (!response.body) {
    return true;
  }

  const headerAsEmpty = response.headers.get('Content-Length') === '0';

  if (headerAsEmpty) {
    return true;
  } // Clone response to read it
  // because response can be read only once


  const clonnedResponse = response.clone();
  const bodyAsText = await clonnedResponse.text();

  if (bodyAsText.length === 0) {
    return true;
  }

  return false;
}

function createJsonQuery(config) {
  var _a, _b, _c, _d, _e, _f;

  const credentials = (_a = config.request.credentials) !== null && _a !== void 0 ? _a : 'same-origin'; // Basement

  const requestFx = createJsonApiRequest({
    request: {
      method: config.request.method,
      credentials
    },
    concurrency: {
      strategy: (_c = (_b = config.concurrency) === null || _b === void 0 ? void 0 : _b.strategy) !== null && _c !== void 0 ? _c : 'TAKE_LATEST'
    },
    abort: {
      clock: (_d = config.concurrency) === null || _d === void 0 ? void 0 : _d.abort
    }
  }); // Connections

  const internalStart = createEvent();
  const headlessQuery = createHeadlessQuery({
    initialData: config.initialData,
    contract: (_e = config.response.contract) !== null && _e !== void 0 ? _e : unknownContract,
    mapData: (_f = config.response.mapData) !== null && _f !== void 0 ? _f : ({
      result
    }) => result,
    validate: config.response.validate,
    enabled: config.enabled,
    name: config.name,
    serialize: config.serialize,
    sourced: [config.request.url, config.request.body, config.request.headers, config.request.query],
    paramsAreMeaningless: true
  });

  headlessQuery.__.executeFx.use(attach({
    source: {
      url: normalizeSourced({
        field: config.request.url,
        clock: internalStart
      }),
      body: normalizeSourced({
        field: config.request.body,
        clock: internalStart
      }),
      headers: normalizeSourced({
        field: config.request.headers,
        clock: internalStart
      }),
      query: normalizeSourced({
        field: config.request.query,
        clock: internalStart
      })
    },
    effect: requestFx
  }));

  sample({
    clock: [headlessQuery.start, headlessQuery.__.executeFx],
    target: internalStart,
    greedy: true
  });
  return _extends({}, headlessQuery, {
    __: _extends({}, headlessQuery.__, {
      executeFx: requestFx
    })
  });
}

const MutationSymbol = Symbol('Mutation');

const _excluded = ["params"];
function createHeadlessMutation(config) {
  const {
    name,
    enabled,
    contract,
    validate,
    mapData
  } = config;
  const operation = createRemoteOperation({
    name,
    serialize: 'ignore',
    enabled,
    kind: MutationSymbol,
    meta: null,
    contract,
    validate,
    mapData
  }); // -- Protocols --

  const unitShape = {
    pending: operation.$pending,
    start: operation.start
  };

  const unitShapeProtocol = () => unitShape; // Experimental API, won't be exposed as protocol for now


  const attachProtocol = ({
    source,
    mapParams
  }) => {
    const attachedMutation = createHeadlessMutation(config);

    attachedMutation.__.lowLevelAPI.dataSourceRetrieverFx.use(attach({
      source,
      mapParams: (_ref, sourceValue) => {
        let {
          params
        } = _ref,
            rest = _objectWithoutPropertiesLoose(_ref, _excluded);

        return _extends({
          params: mapParams ? mapParams(params, sourceValue) : params
        }, rest);
      },
      effect: operation.__.lowLevelAPI.dataSourceRetrieverFx
    }));

    return attachedMutation;
  }; // -- Public API --


  return _extends({}, operation, {
    __: _extends({}, operation.__, {
      experimentalAPI: {
        attach: attachProtocol
      }
    }),
    '@@unitShape': unitShapeProtocol
  });
}

function createMutation( // Use any because of overloads
// eslint-disable-next-line @typescript-eslint/no-explicit-any
config) {
  var _a;

  const mutation = createHeadlessMutation({
    name: config.name,
    enabled: config.enabled,
    contract: (_a = config.contract) !== null && _a !== void 0 ? _a : unknownContract,
    mapData: ({
      result
    }) => result
  });

  mutation.__.executeFx.use(resolveExecuteEffect(config));

  return mutation;
}

function createJsonMutation(config) {
  var _a, _b, _c, _d;

  const credentials = (_a = config.request.credentials) !== null && _a !== void 0 ? _a : 'same-origin';
  const requestFx = createJsonApiRequest({
    request: {
      method: config.request.method,
      credentials
    },
    concurrency: {
      strategy: 'TAKE_EVERY'
    },
    response: {
      status: config.response.status
    },
    abort: {
      clock: (_b = config.concurrency) === null || _b === void 0 ? void 0 : _b.abort
    }
  });
  const headlessMutation = createHeadlessMutation({
    contract: (_c = config.response.contract) !== null && _c !== void 0 ? _c : unknownContract,
    mapData: (_d = config.response.mapData) !== null && _d !== void 0 ? _d : ({
      result
    }) => result,
    validate: config.response.validate,
    enabled: config.enabled,
    name: config.name
  });
  const internalStart = createEvent();

  headlessMutation.__.executeFx.use(attach({
    source: {
      url: normalizeSourced({
        field: config.request.url,
        clock: internalStart
      }),
      body: normalizeSourced({
        field: config.request.body,
        clock: internalStart
      }),
      headers: normalizeSourced({
        field: config.request.headers,
        clock: internalStart
      }),
      query: normalizeSourced({
        field: config.request.query,
        clock: internalStart
      })
    },
    effect: requestFx
  }));

  sample({
    clock: [headlessMutation.start, headlessMutation.__.executeFx],
    target: internalStart,
    greedy: true
  });
  return _extends({}, headlessMutation, {
    __: _extends({}, headlessMutation.__, {
      executeFx: requestFx
    })
  });
}

const millisecondUnits = ['ms', 'milli', 'millisecond', 'milliseconds'];
const secUnits = ['s', 'sec', 'secs', 'second', 'seconds'];
const minUnits = ['m', 'min', 'mins', 'minute', 'minutes'];
const hourUnits = ['h', 'hr', 'hrs', 'hour', 'hours'];
function parseTime(time) {
  if (typeof time === 'number') {
    return time;
  }

  let result = 0;

  for (const part of time.split(' ')) {
    switch (true) {
      case hasEnding(part, millisecondUnits):
        result += parseNumber(part);
        break;

      case hasEnding(part, secUnits):
        result += parseNumber(part) * 1000;
        break;

      case hasEnding(part, minUnits):
        result += parseNumber(part) * 60000;
        break;

      case hasEnding(part, hourUnits):
        result += parseNumber(part) * 3600000;
        break;
    }
  }

  return result;
}

function hasEnding(value, allowedEndings) {
  return allowedEndings.includes(extractNonNumeric(value));
}

function extractNonNumeric(value) {
  return value.replace(/[0-9.]/g, '');
}

function parseNumber(value) {
  return value.includes('.') ? parseFloat(value) : parseInt(value);
}

function retry(operation, {
  times,
  delay: timeout,
  filter,
  mapParams,
  otherwise
}) {
  const $maxAttempts = normalizeStaticOrReactive(times);
  const $attempt = createStore(1, {
    serialize: 'ignore'
  });
  const $meta = combine({
    attempt: $attempt
  });
  const newAttempt = createEvent();
  const {
    planNextAttempt,
    __: retriesAreOver
  } = split(sample({
    clock: operation.finished.failure,
    source: {
      maxAttempts: $maxAttempts,
      attempt: $attempt
    },
    filter: normalizeSourced({
      field: filter !== null && filter !== void 0 ? filter : true,
      clock: operation.finished.failure
    }),
    fn: ({
      attempt,
      maxAttempts
    }, {
      params,
      error
    }) => ({
      params,
      error,
      meta: {
        attempt,
        maxAttempts
      }
    })
  }), {
    planNextAttempt: ({
      meta
    }) => meta.attempt <= meta.maxAttempts
  });
  sample({
    clock: delay({
      clock: sample({
        clock: planNextAttempt,
        source: normalizeSourced({
          field: mapParams !== null && mapParams !== void 0 ? mapParams : ({
            params
          }) => params,
          clock: planNextAttempt
        })
      }),
      timeout: normalizeSourced({
        field: timeout,
        source: $meta
      }).map(parseTime)
    }),
    target: [newAttempt, operation.start]
  });
  $attempt.on(newAttempt, attempt => attempt + 1).reset(operation.finished.success);

  if (otherwise) {
    sample({
      clock: retriesAreOver,
      target: otherwise
    });
  }
}

const defaultOptions = {
  randomize: {
    spread: 0
  }
};
function linearDelay(base, opts = defaultOptions) {
  return function ({
    attempt
  }) {
    return base * attempt + randomAddition(opts);
  };
}
function exponentialDelay(base, opts = defaultOptions) {
  return function ({
    attempt
  }) {
    return base ** attempt + randomAddition(opts);
  };
}

function randomAddition({
  randomize
}) {
  const {
    spread
  } = randomize;
  return randomNumber({
    min: -spread,
    max: spread
  });
}

function update(query, {
  on: mutation,
  by: rules
}) {
  const $queryState = queryState(query);
  const fillQueryData = createEvent();
  const fillQueryError = createEvent();
  split({
    source: sample({
      clock: mutation.finished.success,
      source: normalizeSourced({
        field: rules.success,
        clock: sample({
          clock: mutation.finished.success,
          source: $queryState,
          fn: (query, {
            result,
            params
          }) => ({
            query,
            mutation: {
              result,
              params: params !== null && params !== void 0 ? params : null
            }
          })
        })
      })
    }),
    match: {
      fillData: payload => isNotEmpty(payload.result)
    },
    cases: {
      fillData: fillQueryData,
      __: fillQueryError
    }
  });

  if (rules.failure) {
    split({
      source: sample({
        clock: mutation.finished.failure,
        source: normalizeSourced({
          field: rules.failure,
          clock: sample({
            clock: mutation.finished.failure,
            source: $queryState,
            fn: (query, {
              error,
              params
            }) => ({
              query,
              mutation: {
                error,
                params: params !== null && params !== void 0 ? params : null
              }
            })
          })
        })
      }),
      match: {
        fillData: payload => isNotEmpty(payload.result)
      },
      cases: {
        fillData: fillQueryData,
        __: fillQueryError
      }
    });
  }

  sample({
    clock: fillQueryData,
    fn: ({
      result
    }) => result,
    target: [query.$data, query.$error.reinit]
  });
  sample({
    clock: fillQueryError,
    fn: ({
      error
    }) => error,
    target: [query.$error, query.$data.reinit]
  }); // -- Refetching

  const {
    shouldRefetch,
    __: shouldNotRefetch
  } = split(merge([fillQueryData, fillQueryError]).map(({
    refetch
  }) => refetch), {
    shouldRefetch: refetch => Boolean(refetch)
  });
  sample({
    clock: shouldRefetch,
    source: $queryState,
    fn: (state, refetch) => {
      if (typeof refetch === 'object' && 'params' in refetch) {
        return {
          params: refetch.params,
          refresh: true
        };
      }

      return {
        params: state === null || state === void 0 ? void 0 : state.params,
        refresh: true
      };
    },
    target: [query.__.lowLevelAPI.revalidate, query.$stale.reinit]
  });
  sample({
    clock: shouldNotRefetch,
    source: $queryState,
    filter: Boolean,
    fn: state => ({
      params: state.params,
      refresh: false
    }),
    target: query.__.lowLevelAPI.revalidate
  });
}

function queryState(query) {
  return combine({
    result: query.$data,
    params: query.__.$latestParams,
    error: query.$error,
    failed: query.$failed
  }, ({
    result,
    params,
    error,
    failed
  }) => {
    if (!result && !error) {
      return null;
    }

    return failed ? {
      error,
      params: params
    } : {
      result,
      params: params
    };
  });
}

function attachOperation(operation, config) {
  var _a;

  const {
    source,
    mapParams
  } = config !== null && config !== void 0 ? config : {};
  return (_a = operation.__.experimentalAPI) === null || _a === void 0 ? void 0 : _a.attach({
    source: source !== null && source !== void 0 ? source : createStore(null, {
      serialize: 'ignore'
    }),
    mapParams: mapParams !== null && mapParams !== void 0 ? mapParams : v => v
  });
}

function createCacheAdapter(adapter) {
  const $instance = createStore(adapter, {
    serialize: 'ignore',
    sid: 'ff.cache_instance'
  });
  return _extends({}, adapter, {
    __: {
      $instance
    }
  });
}

function attachObservability({
  adapter,
  options,
  events
}) {
  if (options === null || options === void 0 ? void 0 : options.hit) {
    sample({
      clock: adapter.get.done,
      filter: ({
        result
      }) => result !== null,
      fn: ({
        params
      }) => ({
        key: params.key
      }),
      target: options.hit
    });
  }

  if (options === null || options === void 0 ? void 0 : options.miss) {
    sample({
      clock: adapter.get.done,
      filter: ({
        result
      }) => result === null,
      fn: ({
        params
      }) => ({
        key: params.key
      }),
      target: options.miss
    });
  }

  if ((options === null || options === void 0 ? void 0 : options.expired) && (events === null || events === void 0 ? void 0 : events.itemExpired)) {
    sample({
      clock: events.itemExpired,
      fn: ({
        key
      }) => ({
        key
      }),
      target: options.expired
    });
  }

  if ((options === null || options === void 0 ? void 0 : options.evicted) && (events === null || events === void 0 ? void 0 : events.itemEvicted)) {
    sample({
      clock: events.itemEvicted,
      target: options.evicted
    });
  }
}

function inMemoryCache(config) {
  const {
    maxEntries,
    maxAge,
    observability
  } = config !== null && config !== void 0 ? config : {};
  let storage = {};
  const saveValue = createEvent();
  const removeValue = createEvent();
  const itemExpired = createEvent();
  const itemEvicted = createEvent();
  const purge = createEvent();
  purge.watch(() => {
    storage = {};
  });
  const $now = time({
    clock: saveValue
  });
  const maxEntriesApplied = sample({
    clock: saveValue,
    source: {
      now: $now
    },
    fn: ({
      now
    }, {
      key,
      value
    }) => applyMaxEntries(storage, {
      key,
      entry: {
        value,
        cachedAt: now
      }
    }, maxEntries)
  });
  maxEntriesApplied.watch(({
    next
  }) => {
    storage = next;
  });
  sample({
    clock: maxEntriesApplied,
    filter: ({
      evicted
    }) => !!evicted,
    fn: ({
      evicted
    }) => ({
      key: evicted
    }),
    target: itemEvicted
  });
  removeValue.watch(({
    key
  }) => {
    const rest = _objectWithoutPropertiesLoose(storage, [key].map(_toPropertyKey));

    storage = rest;
  });

  if (maxAge) {
    const timeout = parseTime(maxAge);
    saveValue.watch(payload => {
      const boundItemExpired = scopeBind(itemExpired, {
        safe: true
      });
      setTimeout(() => boundItemExpired(payload), timeout);
    });
    sample({
      clock: itemExpired,
      fn: ({
        key
      }) => ({
        key
      }),
      target: removeValue
    });
  }

  const adapter = {
    get: createEffect(({
      key
    }) => {
      var _a;

      const saved = (_a = storage[key]) !== null && _a !== void 0 ? _a : null;

      if (!saved) {
        return null;
      }

      if (maxAge) {
        const expiredAt = (saved === null || saved === void 0 ? void 0 : saved.cachedAt) + parseTime(maxAge);

        if (Date.now() >= expiredAt) {
          removeValue({
            key
          });
          return null;
        }
      }

      return saved;
    }),
    set: createEffect(saveValue),
    unset: createEffect(removeValue),
    purge
  };
  attachObservability({
    adapter,
    options: observability,
    events: {
      itemExpired,
      itemEvicted
    }
  });
  return createCacheAdapter(adapter);
}

function applyMaxEntries(storage, {
  key,
  entry
}, maxEntries) {
  if (maxEntries === undefined) return {
    next: _extends({}, storage, {
      [key]: entry
    }),
    evicted: null
  };
  const keys = Object.keys(storage);
  if (keys.length < maxEntries) return {
    next: _extends({}, storage, {
      [key]: entry
    }),
    evicted: null
  };
  const [firstKey] = keys;

  const rest = _objectWithoutPropertiesLoose(storage, [firstKey].map(_toPropertyKey));

  return {
    next: _extends({}, rest, {
      [key]: entry
    }),
    evicted: firstKey
  };
}

// Copied from http://www.movable-type.co.uk/scripts/sha1.html

/**
 * Generates SHA-1 hash of string
 */
function sha1(source) {
  // convert string to UTF-8, as SHA only deals with byte-streams
  let msg = encodeUTF8(source); // constants [§4.2.1]

  const K = [0x5a827999, 0x6ed9eba1, 0x8f1bbcdc, 0xca62c1d6]; // PREPROCESSING

  msg += String.fromCharCode(0x80); // add trailing '1' bit (+ 0's padding) to string [§5.1.1]
  // convert string msg into 512-bit/16-integer blocks arrays of ints [§5.2.1]

  const l = msg.length / 4 + 2; // length (in 32-bit integers) of msg + ‘1’ + appended length

  const N = Math.ceil(l / 16); // number of 16-integer-blocks required to hold 'l' ints

  const M = new Array(N);

  for (let i = 0; i < N; i++) {
    M[i] = new Array(16);

    for (let j = 0; j < 16; j++) {
      // encode 4 chars per integer, big-endian encoding
      M[i][j] = msg.charCodeAt(i * 64 + j * 4) << 24 | msg.charCodeAt(i * 64 + j * 4 + 1) << 16 | msg.charCodeAt(i * 64 + j * 4 + 2) << 8 | msg.charCodeAt(i * 64 + j * 4 + 3);
    } // note running off the end of msg is ok 'cos bitwise ops on NaN return 0

  } // add length (in bits) into final pair of 32-bit integers (big-endian) [§5.1.1]
  // note: most significant word would be (len-1)*8 >>> 32, but since JS converts
  // bitwise-op args to 32 bits, we need to simulate this by arithmetic operators


  M[N - 1][14] = (msg.length - 1) * 8 / Math.pow(2, 32);
  M[N - 1][14] = Math.floor(M[N - 1][14]);
  M[N - 1][15] = (msg.length - 1) * 8 & 0xffffffff; // set initial hash value [§5.3.1]

  let H0 = 0x67452301;
  let H1 = 0xefcdab89;
  let H2 = 0x98badcfe;
  let H3 = 0x10325476;
  let H4 = 0xc3d2e1f0; // HASH COMPUTATION [§6.1.2]

  const W = new Array(80);
  let a, b, c, d, e;

  for (let i = 0; i < N; i++) {
    // 1 - prepare message schedule 'W'
    for (let t = 0; t < 16; t++) W[t] = M[i][t];

    for (let t = 16; t < 80; t++) W[t] = ROTL(W[t - 3] ^ W[t - 8] ^ W[t - 14] ^ W[t - 16], 1); // 2 - initialise five working variables a, b, c, d, e with previous hash value


    a = H0;
    b = H1;
    c = H2;
    d = H3;
    e = H4; // 3 - main loop

    for (let t = 0; t < 80; t++) {
      // seq for blocks of 'f' functions and 'K' constants
      const s = Math.floor(t / 20); // it is safe to use  0 | 1 | 2 | 3 because of max value of t is 79

      const T = ROTL(a, 5) + f(s, b, c, d) + e + K[s] + W[t] & 0xffffffff;
      e = d;
      d = c;
      c = ROTL(b, 30);
      b = a;
      a = T;
    } // 4 - compute the new intermediate hash value


    H0 = H0 + a & 0xffffffff; // note 'addition modulo 2^32'

    H1 = H1 + b & 0xffffffff;
    H2 = H2 + c & 0xffffffff;
    H3 = H3 + d & 0xffffffff;
    H4 = H4 + e & 0xffffffff;
  }

  return toHexString(H0) + toHexString(H1) + toHexString(H2) + toHexString(H3) + toHexString(H4);
} //
// function 'f' [§4.1.1]
//

function f(s, x, y, z) {
  switch (s) {
    case 0:
      return x & y ^ ~x & z;
    // Ch()

    case 1:
      return x ^ y ^ z;
    // Parity()

    case 2:
      return x & y ^ x & z ^ y & z;
    // Maj()

    case 3:
      return x ^ y ^ z;
    // Parity()
  }
}
/**
 * rotate left (circular left shift) value x by n positions [§3.2.5]
 */


function ROTL(x, n) {
  return x << n | x >>> 32 - n;
}
/**
 * hexadecimal representation of a number
 */


function toHexString(n) {
  let s = '';
  let v;

  for (let i = 7; i >= 0; i--) {
    v = n >>> i * 4 & 0xf;
    s += v.toString(16);
  }

  return s;
}
/**
 * Encode multi-byte Unicode string into utf-8 multiple single-byte characters
 * (BMP / basic multilingual plane only)
 *
 * Chars in range U+0080 - U+07FF are encoded in 2 chars, U+0800 - U+FFFF in 3 chars
 *
 * @param {String} unicodeString Unicode string to be encoded as UTF-8
 * @returns {String} encoded string
 */


function encodeUTF8(unicodeString) {
  return unicodeString.replace(/[\u0080-\u07ff]/g, // U+0080 - U+07FF => 2 bytes 110yyyyy, 10zzzzzz
  c => {
    const cc = c.charCodeAt(0);
    return String.fromCharCode(0xc0 | cc >> 6, 0x80 | cc & 0x3f);
  }).replace(/[\u0800-\uffff]/g, // U+0800 - U+FFFF => 3 bytes 1110xxxx, 10yyyyyy, 10zzzzzz
  function (c) {
    const cc = c.charCodeAt(0);
    return String.fromCharCode(0xe0 | cc >> 12, 0x80 | cc >> 6 & 0x3f, 0x80 | cc & 0x3f);
  });
}

function stableStringify(data) {
  const seen = new Set();

  function stringify(node) {
    if (node === undefined) return;
    if (node === null) return 'null';

    if (typeof node === 'number') {
      return isFinite(node) ? `${node}` : 'null';
    }

    if (typeof node === 'function') {
      throw new TypeError(`Can't serialize function`);
    }

    if (typeof node !== 'object') return JSON.stringify(node);

    if (seen.has(node)) {
      throw new TypeError(`Can't serialize cyclic structure`);
    }

    seen.add(node);

    if (Array.isArray(node)) {
      const _values = node.map(v => stringify(v) || 'null').join(',');

      seen.delete(node);
      return `[${_values}]`;
    }

    const values = Object.keys(node).sort().map(key => {
      // @ts-expect-error We're working with unknown object
      const value = stringify(node[key]);
      return value ? `${stringify(key)}:${value}` : '';
    }).filter(Boolean).join(',');
    seen.delete(node);
    return `{${values}}`;
  }

  return stringify(data);
}

function createKey({
  sid,
  params = null,
  sources
}) {
  try {
    const stableString = stableStringify({
      params,
      sources,
      sid
    });
    return sha1(stableString);
  } catch (e) {
    return null;
  }
}
function queryUniqId(query) {
  const sid = querySid(query);

  if (sid) {
    return sid;
  }

  const uniqName = queryUniqName(query);

  if (uniqName) {
    return uniqName;
  }

  throw new Error('Query does not have sid or uniq name, which is required for caching, read more https://farfetched.pages.dev/recipes/sids.html');
}

function querySid(query) {
  const sid = query.$data.sid;

  if (!(sid === null || sid === void 0 ? void 0 : sid.includes('|'))) {
    return null;
  }

  return sid;
}

const prevNames = new Set();

function queryUniqName(query) {
  const name = query.__.meta.name;

  if (prevNames.has(name)) {
    return null;
  }

  prevNames.add(name);
  return name;
}

function cache(query, rawParams) {
  var _a;

  const {
    adapter,
    staleAfter,
    purge
  } = _extends({
    adapter: (_a = rawParams === null || rawParams === void 0 ? void 0 : rawParams.adapter) !== null && _a !== void 0 ? _a : inMemoryCache()
  }, rawParams);

  const id = queryUniqId(query);

  const sourcedReaders = query.__.lowLevelAPI.sourced.map(createSourcedReader);

  const readAllSourcedFx = createEffect(async params => {
    return Promise.all(sourcedReaders.map(readerFx => readerFx(params)));
  });
  const unsetFx = createEffect(async ({
    instance,
    params
  }) => {
    const sources = await readAllSourcedFx(params);
    const key = createKey({
      sid: id,
      params: query.__.lowLevelAPI.paramsAreMeaningless ? null : params,
      sources
    });

    if (!key) {
      return;
    }

    await instance.unset({
      key
    });
  });
  const setFx = createEffect(async ({
    instance,
    params,
    result
  }) => {
    const sources = await readAllSourcedFx(params);
    const key = createKey({
      sid: id,
      params: query.__.lowLevelAPI.paramsAreMeaningless ? null : params,
      sources
    });

    if (!key) {
      return;
    }

    await instance.set({
      key,
      value: result
    });
  });
  const getFx = createEffect(async ({
    params,
    instance
  }) => {
    const sources = await readAllSourcedFx(params);
    const key = createKey({
      sid: id,
      params: query.__.lowLevelAPI.paramsAreMeaningless ? null : params,
      sources
    });

    if (!key) {
      return null;
    }

    const result = await instance.get({
      key
    });

    if (!result) {
      return null;
    }

    const stale = staleAfter ? result.cachedAt + parseTime(staleAfter) <= Date.now() : true;
    return {
      result: result.value,
      stale
    };
  });
  const cacheDatSource = {
    name: 'cache',
    get: attach({
      source: {
        instance: adapter.__.$instance
      },
      mapParams: ({
        params
      }, {
        instance
      }) => ({
        params,
        instance
      }),
      effect: getFx
    }),
    set: attach({
      source: {
        instance: adapter.__.$instance
      },
      mapParams: ({
        params,
        result
      }, {
        instance
      }) => ({
        params,
        result,
        instance
      }),
      effect: setFx
    }),
    unset: attach({
      source: {
        instance: adapter.__.$instance
      },
      mapParams: ({
        params
      }, {
        instance
      }) => ({
        instance,
        params
      }),
      effect: unsetFx
    })
  };

  query.__.lowLevelAPI.dataSources.unshift(cacheDatSource);

  if (purge) {
    sample({
      clock: purge,
      source: {
        instance: adapter.__.$instance
      },
      target: createEffect(({
        instance
      }) => instance.purge())
    });
  }
}

/**
 * @deprecated Write your own adapter instead by recipe — https://farfetched.pages.dev/recipes/server_cache.html
 */

function externalCache(config) {
  const purge = createEvent();
  const purgeFx = createEffect(config.purge);
  sample({
    clock: purge,
    target: purgeFx
  });
  const adapter = {
    get: createEffect(config.get),
    set: createEffect(config.set),
    unset: createEffect(config.unset),
    purge
  };
  attachObservability({
    adapter,
    options: config.observability
  });
  return createCacheAdapter(adapter);
}

const META_KEY = '__farfetched_meta__';
function browserStorageCache(config) {
  const {
    storage,
    observability,
    maxAge,
    maxEntries
  } = config; // -- adapter

  function storageCache() {
    const getSavedItemFx = createEffect(async key => {
      const item = await getItemFx(key);
      if (!item) return null;

      try {
        const parsed = JSON.parse(item);
        return parsed;
      } catch (_a) {
        return null;
      }
    });
    const setSavedItemFx = createEffect(async ({
      key,
      value
    }) => {
      const item = JSON.stringify({
        value,
        timestamp: Date.now()
      });
      metaStorage.addKey({
        key
      });
      await setItemFx({
        key,
        value: item
      });
    });
    const removeSavedItemFx = createEffect(async key => {
      metaStorage.removeKey({
        key
      });
      await removeItemFx(key);
    });
    const itemExpired = createEvent();
    const itemEvicted = createEvent();
    const purge = createEvent();
    const purgeFx = createEffect(async keys => Promise.all(keys.map(removeSavedItemFx)));
    sample({
      clock: purge,
      source: metaStorage.$meta,
      fn: meta => {
        var _a;

        return (_a = meta === null || meta === void 0 ? void 0 : meta.keys) !== null && _a !== void 0 ? _a : [];
      },
      target: purgeFx
    });

    if (maxAge) {
      sample({
        clock: delay({
          clock: sample({
            clock: setItemFx.done,
            filter: ({
              params
            }) => params.key !== META_KEY
          }),
          timeout: parseTime(maxAge)
        }),
        fn: get('params'),
        target: [itemExpired, removeSavedItemFx]
      });
    }

    const adapter = {
      get: createEffect(async ({
        key
      }) => {
        const saved = await getSavedItemFx(key);
        if (!saved) return null;

        if (maxAge) {
          const expiredAt = (saved === null || saved === void 0 ? void 0 : saved.timestamp) + parseTime(maxAge);

          if (Date.now() >= expiredAt) {
            itemExpired({
              key,
              value: saved.value
            });
            await removeSavedItemFx(key);
            return null;
          }
        }

        return {
          value: saved.value,
          cachedAt: saved.timestamp
        };
      }),
      set: createEffect(async ({
        key,
        value
      }) => {
        var _a, _b, _c;

        const meta = await getMetaFx();
        const keysAmount = (_b = (_a = meta === null || meta === void 0 ? void 0 : meta.keys) === null || _a === void 0 ? void 0 : _a.length) !== null && _b !== void 0 ? _b : 0;

        if (maxEntries && keysAmount >= maxEntries) {
          const forDelete = (_c = meta === null || meta === void 0 ? void 0 : meta.keys) === null || _c === void 0 ? void 0 : _c.slice(0, keysAmount - maxEntries + 1);

          for (const _key of forDelete !== null && forDelete !== void 0 ? forDelete : []) {
            itemEvicted({
              key: _key
            });
            await removeSavedItemFx(_key);
          }
        }

        await setSavedItemFx({
          key,
          value
        });
      }),
      unset: createEffect(async ({
        key
      }) => {
        await removeSavedItemFx(key);
      }),
      purge
    };
    attachObservability({
      adapter,
      options: observability,
      events: {
        itemExpired,
        itemEvicted
      }
    });
    return createCacheAdapter(adapter);
  } // -- meta storage


  const $meta = createStore(null, {
    serialize: 'ignore'
  });
  const getMetaFx = createEffect(async () => {
    const meta = await getItemFx(META_KEY);
    if (!meta) return null;

    try {
      const parsed = JSON.parse(meta);
      return parsed;
    } catch (_a) {
      return null;
    }
  });
  const setMetaFx = createEffect(meta => setItemFx({
    key: META_KEY,
    value: JSON.stringify(meta)
  }));
  const addKey = createEvent();
  const removeKey = createEvent();
  const metaStorage = {
    $meta,
    addKey,
    removeKey
  };
  sample({
    clock: getMetaFx.doneData,
    target: $meta
  });
  sample({
    clock: $meta,
    filter: Boolean,
    target: setMetaFx
  });
  sample({
    clock: addKey,
    source: $meta,
    fn: (meta, {
      key
    }) => {
      var _a;

      const knownKeys = (_a = meta === null || meta === void 0 ? void 0 : meta.keys) !== null && _a !== void 0 ? _a : [];

      if (knownKeys.includes(key)) {
        return meta;
      }

      return _extends({}, meta, {
        keys: [...knownKeys, key]
      });
    },
    target: $meta
  });
  sample({
    clock: removeKey,
    source: $meta,
    fn: (meta, {
      key
    }) => {
      var _a, _b;

      return _extends({}, meta, {
        keys: (_b = (_a = meta === null || meta === void 0 ? void 0 : meta.keys) === null || _a === void 0 ? void 0 : _a.filter(k => k !== key)) !== null && _b !== void 0 ? _b : []
      });
    },
    target: $meta
  }); // -- storage effects

  const setItemFx = createEffect(params => {
    storage().setItem(params.key, params.value);
  });
  const getItemFx = createEffect(key => storage().getItem(key));
  const removeItemFx = createEffect(key => storage().removeItem(key)); // public

  return storageCache();
}

function localStorageCache(config) {
  return browserStorageCache(_extends({
    storage: () => localStorage
  }, config));
}

function sessionStorageCache(config) {
  return browserStorageCache(_extends({
    storage: () => sessionStorage
  }, config));
}

function voidCache() {
  return createCacheAdapter({
    get: createEffect(() => null),
    set: createEffect(() => {// pass
    }),
    purge: createEvent(),
    unset: createEffect()
  });
}

function declareParams() {
  return createEvent();
}

function keepFresh(query, config) {
  var _a;

  const triggers = [];
  const [triggerEvents, protocolCompatibleObjects] = divide((_a = config.triggers) !== null && _a !== void 0 ? _a : [], is.event);
  triggers.push(...triggerEvents);

  if (protocolCompatibleObjects.length > 0) {
    const triggersByProtocol = protocolCompatibleObjects.map(trigger => trigger['@@trigger']());
    const $alreadySetup = createStore(false, {
      serialize: 'ignore'
    });
    const {
      setup,
      teardown
    } = createApi($alreadySetup, {
      setup: () => true,
      teardown: () => false
    });
    sample({
      clock: [query.finished.success, sample({
        clock: query.$enabled.updates,
        filter: query.$enabled
      })],
      filter: not($alreadySetup),
      target: [...triggersByProtocol.map(get('setup')), setup]
    });
    sample({
      clock: query.$enabled.updates,
      filter: and($alreadySetup, not(query.$enabled)),
      target: [...triggersByProtocol.map(get('teardown')), teardown]
    });
    triggers.push(...triggersByProtocol.map(get('fired')));
  }

  if (config.automatically) {
    const finalyParams = query.finished.finally.map(get('params'));
    const $previousSources = createStore([], {
      serialize: 'ignore'
    }); // @ts-expect-error I have no idea

    sample({
      clock: finalyParams,
      source: combine(query.__.lowLevelAPI.sourced.map(sourced => normalizeSourced({
        field: sourced,
        clock: finalyParams
      }))),
      filter: query.$enabled,
      target: $previousSources
    });
    const sourcesUpdated = sample({
      clock: query.__.lowLevelAPI.sourced.map(extractSource).filter(is.store),
      source: query.__.$latestParams,
      filter: not(query.$idle),
      fn: params => params
    });
    const $nextSources = combine(query.__.lowLevelAPI.sourced.map(sourced => normalizeSourced({
      field: sourced,
      clock: sourcesUpdated
    })));
    triggers.push(sample({
      clock: [$nextSources.updates, query.$enabled.updates.filter({
        fn: Boolean
      })],
      source: [$nextSources, $previousSources],
      filter: ([next, prev]) => !isEqual(next, prev)
    }));
  }

  const forceFresh = sample({
    clock: triggers,
    filter: query.$enabled
  });
  sample({
    clock: forceFresh,
    filter: not(query.$idle),
    fn: () => true,
    target: query.$stale
  }); // @ts-expect-error TS cannot get that if query.$idle is false, then $latestParams is Params

  sample({
    clock: syncBatch(forceFresh),
    source: query.__.$latestParams,
    filter: not(query.$idle),
    target: query.refresh
  });
}

export { abortError, attachOperation, cache, combineSourced, connectQuery, createCacheAdapter, createHeadlessMutation, createHeadlessQuery, createJsonMutation, createJsonQuery, createMutation, createQuery, declareParams, exponentialDelay, externalCache, fetchFx, httpError, inMemoryCache, invalidDataError, isAbortError, isHttpError, isHttpErrorCode, isInvalidDataError, isNetworkError, isPreparationError, isTimeoutError, keepFresh, linearDelay, localStorageCache, networkError, normalizeSourced, preparationError, retry, sessionStorageCache, timeoutError, unknownContract, update, voidCache };
